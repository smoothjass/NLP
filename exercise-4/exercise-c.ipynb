{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Exercise C.1: Preprocessing\n",
    "1. Preprocess the data.\n",
    "2. Use LDA on the data.\n",
    "3. Perform hyperparameter tuning for the LDA model by varying the number of topics.\n",
    "Hint: The Python package ’gensim.models’ provides the ’LdaModel’ function."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcedd4961ed24a0a"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models import LdaModel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:11.973358Z",
     "start_time": "2023-10-24T08:40:11.801328900Z"
    }
   },
   "id": "d77d9f6347728f91"
  },
  {
   "cell_type": "markdown",
   "source": [
    "first i will take a look a the example from gensim to see how this works and then next, use the plot summaries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9d1ca3545c681e6"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# Create a corpus from a list of texts\n",
    "common_dictionary = Dictionary(common_texts)\n",
    "common_corpus = [common_dictionary.doc2bow(text) for text in common_texts]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:12.041360600Z",
     "start_time": "2023-10-24T08:40:11.813324800Z"
    }
   },
   "id": "db645e84f7258942"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# Train the model on the corpus.\n",
    "lda = LdaModel(common_corpus, num_topics=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:12.041360600Z",
     "start_time": "2023-10-24T08:40:11.829326Z"
    }
   },
   "id": "e7cdf9ea3056dc18"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# Create a new corpus, made of previously unseen documents.\n",
    "other_texts = [\n",
    "    ['computer', 'time', 'graph'],\n",
    "    ['survey', 'response', 'eps'],\n",
    "    ['human', 'system', 'computer']\n",
    "]\n",
    "other_corpus = [common_dictionary.doc2bow(text) for text in other_texts]\n",
    "unseen_doc = other_corpus[0]\n",
    "vector = lda[unseen_doc]  # get topic probability distribution for a document"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:12.045363900Z",
     "start_time": "2023-10-24T08:40:11.849334600Z"
    }
   },
   "id": "e4bf6ecf2b76c228"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Update the model by incrementally training on the new corpus\n",
    "lda.update(other_corpus)\n",
    "vector = lda[unseen_doc]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:12.045363900Z",
     "start_time": "2023-10-24T08:40:11.865362900Z"
    }
   },
   "id": "8c79ad98e75661e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "alright now the actual exercise"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b2c33326a982b8f"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# read documents\n",
    "file = open(\"plots_small.txt\", \"r\", encoding=\"utf8\")\n",
    "documents = file.readlines()\n",
    "file.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:12.399537600Z",
     "start_time": "2023-10-24T08:40:11.885363100Z"
    }
   },
   "id": "49996d9c310f8718"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# looking at the data, it seems that sentences don't have full stops. Instead the next sentence starts right after\n",
    "# the last one, with a capital letter, so if we catch camelcase with a regex and but a white space in between, we should be ok\n",
    "import re\n",
    "documents = [re.sub(r'(?<!^)(?=[A-Z])', ' ', document) for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:15.720148100Z",
     "start_time": "2023-10-24T08:40:12.403542900Z"
    }
   },
   "id": "d89f3ca7c659aca"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# lowercase\n",
    "documents = [document.lower() for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:16.096584500Z",
     "start_time": "2023-10-24T08:40:15.720148100Z"
    }
   },
   "id": "cf4d44c200b0941d"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# remove digits\n",
    "documents = [re.sub('\\d+', '', document) for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:17.816144700Z",
     "start_time": "2023-10-24T08:40:16.056568300Z"
    }
   },
   "id": "283c4e9489757fe8"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "import string\n",
    "documents = [re.sub('[%s]' % re.escape(string.punctuation), '', document) for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:18.304258100Z",
     "start_time": "2023-10-24T08:40:17.797844900Z"
    }
   },
   "id": "7c7c37e2d4c9de2a"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# remove extra blanks\n",
    "documents = [re.sub(r'\\t{2,}', ' ', document) for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:19.334353400Z",
     "start_time": "2023-10-24T08:40:18.304258100Z"
    }
   },
   "id": "4dfa42a13e168247"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "documents = [word_tokenize(document) for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:52.008405100Z",
     "start_time": "2023-10-24T08:40:19.342840700Z"
    }
   },
   "id": "5008240a62b72a10"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "from spacy.lang.en import stop_words\n",
    "stopwords = stop_words.STOP_WORDS\n",
    "documents = [[token for token in document if token not in stopwords] for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:40:53.544550300Z",
     "start_time": "2023-10-24T08:40:52.008405100Z"
    }
   },
   "id": "21333b30c3da892c"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# lemmatize tokens\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmtizer = WordNetLemmatizer()\n",
    "documents = [[lemmtizer.lemmatize(lemma) for lemma in document] for document in documents]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:41:14.835801200Z",
     "start_time": "2023-10-24T08:40:53.544550300Z"
    }
   },
   "id": "c7ed9e85cde9017f"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# i think now we're ready for lda\n",
    "del lda\n",
    "# Create a corpus from the documents\n",
    "dictionary = Dictionary(documents)\n",
    "corpus = [dictionary.doc2bow(document) for document in documents]\n",
    "# Train the model on the corpus.\n",
    "lda = LdaModel(corpus, num_topics=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:41:56.573438900Z",
     "start_time": "2023-10-24T08:41:14.835801200Z"
    }
   },
   "id": "721cb9d63e42755c"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "lda_2 = LdaModel(corpus, num_topics=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:42:23.402943400Z",
     "start_time": "2023-10-24T08:41:56.573438900Z"
    }
   },
   "id": "429fc4cd0045e93d"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "lda_3 = LdaModel(corpus, num_topics=15)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:42:57.210823400Z",
     "start_time": "2023-10-24T08:42:23.406945700Z"
    }
   },
   "id": "122327ead8ce4d4d"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T08:42:57.231136900Z",
     "start_time": "2023-10-24T08:42:57.210823400Z"
    }
   },
   "id": "c501f342067b92cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
